kubernates-command
   # kubectl create -f <deploymentfile/svc/configmap/secret/pv/pvc>
   # kubectl get deployment/svc/configmap/secret/pv/pvc/pods
   # kubectl describe pod <pod name>
   # kubectl get pod -o wide
   # kubectl exec -it <pod_name> -- /bin/bash # go inside pod
   # kubectl logs <pod_name>


Docker:
    # docker run -d mysql:latest  # create container in detach mode
    # docker run -d --name mysql -p 3306:3306 mysql:latest
    # docker images # show all images 
    # docker ps # show all running container
    # docker ps -a # show all stop and running container
    # docker run <container-id> # running in foreground
    # docker build -t <dockerhub_id/image_name>:tag . # it will create custom image from dockerfile
    # docker run <image_name> # it will download image and create and run container.
    # docker pull <image_name> # it will pull image
    # docker exec -it <container_id> /bin/bash # go inside container
    # docker run -d -v /opt/path:/var/lib/mysql mysql:latest # persistent volume
    # docker run -it --name <container_name> <image_name> # Create container and go inside the container
    # docker logs <container_name/id> # To check container logs.
    # docker stop container_name_or_id  # stop the container 
    # docker rm container_name_or_id# remive container
    # docker rmi <image_id> # remove image
   # docker inspect container_name_or_id  # Inspect Container Details

ShellScripts:
................
# /bin/bash file.sh
#./file.sh
#!/bin/bash (or) sh.dash
chmod u+x,g-x,o-x filename 
cat /etc/passwd/
chmod 777 filename
chmod +x filename 
.......
chmod u+x filename 
......
chmod= which user and which group and other 
421= read write execute
top command = which process we have running which process talking less memory and more memory......
..........
cpu = nproc 
......
ram = free
....
df = disk space usage 
.....
nproc= print the number processing untis avalible (cpu)
......
free = used the memory in the system 
......
set -x = debug mode for beging shell scripts
......
set -e exit the script when there is an error ..
......
set -o pipefail....
......
ps -ef = check or print the all  prosess id 
......
ps -ef | grep "amazon"

grep= matching patterns file
....
vim test.sh 
12
11.
1
./test.sh | grep 1 
output of the first command to the secound command ...
date | echo "this" 
this is print ...date is a system deafult command ...

Awk command use in specfic retrive in specific colum ..
..........
grep name test
    retrive
ps -ef | grep amazon | awk -f""'{print $2}'
find / slags = everything 
.........
find comand ..find the file
.............
cat logfile | grep error 
logfile storage in google storage and amazon storge ,s3 
curl command 
............
retrive the informatin from internet ...
curl https//with copy the logsfile....| grep error 
postman =api request 
........
python = request module
.......
wget command 
.........
wget _> download -> grep command on downloaded 
download the logfile...

vim ifelse.sh 
a=4
b=10
if [expression]
if [$a>$b]
   then  sdfkkfkk
      dfdggggkd
then 
   echo "a is greater than b"
else ddkkkdkkdkd
else 
echo "b is greater than a"
fi 

#iterations ->for 
for i in {1.100}; do echo $1: done 
for
do increment 
done 
trap command 
...........
trap the signal ........
trap "echo dont use the ctrl+c"sigint
kill -9 java 
.............
sig .. kill command 

AWS(application archtecture} ...
////////////////////////
presntation tier = user interface (fronted) facebook.google..youtube
...........
application tier (backend ) webserver LOAD willbe increase in backend server 
............
data tier (database server) 
.........
load balancer= distribute the multyple server
...............
(USER)CLIENT->INTERNET->LOADBALANCER->SERVERS
...............
              domain name-> IP-> = DNS mapping every project has DNS configuration
ROUNDROBIN ALAGARYTHEM= 1st reqest 1st server 2nd requset 2ndserver to divert the traffic ALL the load balancer used in roundrobbin techinqby deafult
......................
sticktational alagarythem ..1st and 2nd and 3rd requset will go to 1st server that is called 
.........................
why application server runing in the multyple servr becuse of = to handle the traffic


clould computing 
.................
delivery and demanded it resources over the internet rent the software
infrastructure= database , computers, servers,loadbalancing .dns

datacenter = server 
..................

CLOUD PROVIDER 
.................
aws(amazon) ,azure(microsoft),google (gcp),salesforce (salesforce crm)
IBMcloud, oracle ,alibaba cloud, vm cloud...thease all are clould platform in the market
CLOULD computing adavantage.
...........................
pay as you go= howmuch you use u will pay
low cost 
scalability=increse server scale up/down
avalibility=24 hour avilble
reliability=strong 
security=100percent
unlimited storage=
backup= data save

EC2= elasitc clould coumpte is nothing but create unlimtied vm
...........
s3 = unlimited storage 
.......
RDS = relatational data base service mysql
.........
dynomo DB.mango DB = no sql data base 
...........

route53= domain name mapping with ip addres by using route 53.u
.........

EBS = (elastic block store)if you store the data in ec2
......
by default EBS root volume will be attached to e ec2 instance 
linux gives you =8gb 
windows = 30 gb 
EBS= gives you 16 tb 
NOTE: we can increase volume size based on demand
VPC =(VIRTUAL PRIVATE CLOULD)
............................
vpc provides network for ec2 instance all the service behind a private network is called VPC
to connect with EC2 instance we need network for that
LBR
........ loadbalancing used in distribute into multyple server
AUTOscale= loadbalancing purpose 
...............
IAM = identity access management (who can access which service)
.........
Beanstalk = whatevr the infrastructure setup mannualy by use beanstalk to automate
.........
clouldwatch =moniter puropose 
...........
lightsail = deploy applications easly 
.........
SNS = simple notification service 
......

ON PREMISE vs CLOUD
...................
ONpremise is nothing but managed by people it is very costlyy
AMI = amazon machine image 
.........
it provides templatates to launch virtual machine 
EX= windows AMI,AMzon linux ami.ubuntuami,redhat ami,Mac ami
security GROUP
.............
security group are used to allow incoming and outgoing trafic
Inbound rules will maintain incoming traffic rules.
outbound rules will maintain outgoing traffic rules.
windows---->RDP:3389
LINUX------>ssh:22
http-------> http:80
https------->https:443
tomcat------> 8080
KEY-PAIR
.......
key-pair is kind of lock secure our ec2 instance 
key-pair is used to connect with ec2 instance securely
key-pair combination of public -key and privatekey
aws will store public key and it will provide private key for us
using public key and private key we can connect with ec2 instance securely


EC2=vm ----> KEY-PAIR
       ---->security group
       _---->vpc default
       ----->EBS defult
       ------> AMI defult
data center
............
avalibility zone is nothing but data center

EKS
....
eks stands for elastic k8s services
eks is a fully managed aws service
eks is the best place in k8s application becz security,reliability, and scalability
eks can be intregated with other AWS services such as ELB,cloudwatch,Autoscaling,IAM,and vpc
EKS makes it easy to run k8s controllplane across three avalibility zone in order to ensure highavalibility
and it autometically detect and replaces unhelthy masters
aws will have complete control over control plane. we dont have control on control plane
we node to create worker nodes and attach to controll plane
NOTE:we will create worker Nodes group using ASG group
controll plane charges + worker nodde chareges (based on instance type& no of instance)


PRE-Requisites
.............
AWS aacount with admin privilige
instance to manage/access EKS cluster using kubectl
AWS CLI access to use kubectl utility

kubectl(k8s-client-vm) ----> control (aws EKS) plane----->node1 and node2
STEPS TO CREATE EKS CLUSTER IN AWS 
...................................
STEP-1=create vpc using cloud formation (with below s3 url)
URL...
stack Name ..xyz
.................
STEP-2=crate IAM role in AWS
.....................
Entity type: AWS service
select usecase as EKS-->EKS cluster
role name --
STEP-3=cretae EKS cluster using created VPC and IAM role
cluster endpoint access: public & private
step=4 cretate ec2 instance k8s_client_machine

GIT bash COMMANDS 
..............
we are having several git commands to perform operetions with git repo
git help ....
git add .working directory to staging area 
.......
git commit -m "xjjjdk" staging area to local repo 
.............
git push --local repo to remote repo 
.........
git init - it is used to create empty repository or re-initialize existing repo
.........
clone a repo - git clone
..........
create a branch - git branch branch name
..........
switch to branh - git checkout branch name 

git status - this command will display status of current repository
...........
staged files 
...........
files which are added and they are ready to commit 
thies file name will be green colour 

un-staged files
...............
modified files to the local  will be displayed here we need to stage these files to commit.
these files will be displyaed in red colour
un-tracked files   
..............
-newly created files we need to stage them to commit 
these files will be displayed in red colour..

git pull .. to take the code from central repo
rm
git merge
git rebase 
git stash
git add --a -> to add all files at a time 
........
git rm --cached *
..........
git rm -> this command is used to un-stage newly created files
.....
git rm --cached <file name>
........
git remote add <repo-url> (this requires only first time)
..............

git push -u origin master (this is used to move changes from local to central) 
..........................

git reset -> it is used to unstage a file
.........
synatx : git reset HEAD <file-name>

checkout-UNDO
............
git checkout : it is used to discard changes done in a file 
syntax: git checkout --<file name>
git log-> to check commits history we will use git log command 
........
commit-id 
author 
timestamp 
commit msg

git clone 
..........
to take exisiting project from repository to local system we will use git clone command
syntax : git clone <repo-URl>

GIT STASH
........

it is used to record current changes and make working tree clean 
git stash is a TEMPORARY storage ..

working tree ----> his-12 manger assign a task 
the middle man comes to picture git stash 
the working tree will be clean ...
after 12 are completed and ommit and  push it 3 pm.

------> his 10  8am 

-------> 12:12 pm 20 files modifies 

git add --a
git commit -m 
git push
git stash apply 
git stash clear
git stash list 
git stash show 
git stash drop...

WHAT IS BRANCH in github
..............
when we create a git repository by defult it will be provide master branch 
----> branch are nothing but code bases 
----> we can create several branches in git repository
-----> generally in git repository we will create branches like below 
- master (defult)
-devolp ----> on-going dev team, bug fixing team, prod support dev team 
--feature --> story code only vertx code 
--QA
--UAT
-Relese --> deploy into the code relese only 
-prod ...
BRANCH MERGE 
............
feature branches merge into the master branch  we use a cocept call pull request

WORKFLOW 
.........
--> login into reposiotry
---> create devlop branch from master branch
---> clone devlop branch code 
NOTE: 
...... 
if we exucute git clone <repo-url> it clones master branch code by defult
-> if we want to clone specific branch code then we should execute below command
--> git clone  -b <brnch name> <repo-url>

